{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NooAiTdnafkz"
   },
   "source": [
    "# Data Science Unit 1 Sprint Challenge 4\n",
    "\n",
    "## Exploring Data, Testing Hypotheses\n",
    "\n",
    "In this sprint challenge you will look at a dataset of people being approved or rejected for credit.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
    "\n",
    "Data Set Information: This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values.\n",
    "\n",
    "Attribute Information:\n",
    "- A1: b, a.\n",
    "- A2: continuous.\n",
    "- A3: continuous.\n",
    "- A4: u, y, l, t.\n",
    "- A5: g, p, gg.\n",
    "- A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
    "- A7: v, h, bb, j, n, z, dd, ff, o.\n",
    "- A8: continuous.\n",
    "- A9: t, f.\n",
    "- A10: t, f.\n",
    "- A11: continuous.\n",
    "- A12: t, f.\n",
    "- A13: g, p, s.\n",
    "- A14: continuous.\n",
    "- A15: continuous.\n",
    "- A16: +,- (class attribute)\n",
    "\n",
    "Yes, most of that doesn't mean anything. A16 (the class attribute) is the most interesting, as it separates the 307 approved cases from the 383 rejected cases. The remaining variables have been obfuscated for privacy - a challenge you may have to deal with in your data science career.\n",
    "\n",
    "Sprint challenges are evaluated based on satisfactory completion of each part. It is suggested you work through it in order, getting each aspect reasonably working, before trying to deeply explore, iterate, or refine any given step. Once you get to the end, if you want to go back and improve things, go for it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wch6ksCbJtZ"
   },
   "source": [
    "## Part 1 - Load and validate the data\n",
    "\n",
    "- Load the data as a `pandas` data frame.\n",
    "- Validate that it has the appropriate number of observations (you can check the raw file, and also read the dataset description from UCI).\n",
    "- UCI says there should be missing data - check, and if necessary change the data so pandas recognizes it as na\n",
    "- Make sure that the loaded features are of the types described above (continuous values should be treated as float), and correct as necessary\n",
    "\n",
    "This is review, but skills that you'll use at the start of any data exploration. Further, you may have to do some investigation to figure out which file to load from - that is part of the puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q79xDLckzibS",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data as a pandas data frame\n",
    "import pandas as pd\n",
    "credit_names = [\"A\" + str(i) for i in range(1,17)]\n",
    "credit_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data', names = credit_names)\n",
    "credit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validate that it has the appropriate number of observations\n",
    "credit_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    468\n",
       "a    210\n",
       "?     12\n",
       "Name: A1, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values. They are coded as ?s (There are no missing values in A16)\n",
    "credit_data['A1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code ?s as NaN\n",
    "import numpy as np\n",
    "credit_data = credit_data.replace(\"?\", np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1      object\n",
       "A2      object\n",
       "A3     float64\n",
       "A4      object\n",
       "A5      object\n",
       "A6      object\n",
       "A7      object\n",
       "A8     float64\n",
       "A9      object\n",
       "A10     object\n",
       "A11      int64\n",
       "A12     object\n",
       "A13     object\n",
       "A14     object\n",
       "A15      int64\n",
       "A16     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure loaded features are of the types described above.\n",
    "#A2, A11, A14, and A15 need to be fixed\n",
    "credit_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2     float64\n",
       "A11    float64\n",
       "A14    float64\n",
       "A15    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change A2, A11, A14, and A15 to floats\n",
    "fixcols = ['A2', 'A11', 'A14', 'A15']\n",
    "credit_data[fixcols] = credit_data[fixcols].astype(float)\n",
    "credit_data[fixcols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7rLytbrO38L"
   },
   "source": [
    "## Part 2 - Exploring data, Testing hypotheses\n",
    "\n",
    "The only thing we really know about this data is that A16 is the class label. Besides that, we have 6 continuous (float) features and 9 categorical features.\n",
    "\n",
    "Explore the data: you can use whatever approach (tables, utility functions, visualizations) to get an impression of the distributions and relationships of the variables. In general, your goal is to understand how the features are different when grouped by the two class labels (`+` and `-`).\n",
    "\n",
    "For the 6 continuous features, how are they different when split between the two class labels? Choose two features to run t-tests (again split by class label) - specifically, select one feature that is *extremely* different between the classes, and another feature that is notably less different (though perhaps still \"statistically significantly\" different). You may have to explore more than two features to do this.\n",
    "\n",
    "For the categorical features, explore by creating \"cross tabs\" (aka [contingency tables](https://en.wikipedia.org/wiki/Contingency_table)) between them and the class label, and apply the Chi-squared test to them. [pandas.crosstab](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) can create contingency tables, and [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) can calculate the Chi-squared statistic for them.\n",
    "\n",
    "There are 9 categorical features - as with the t-test, try to find one where the Chi-squared test returns an extreme result (rejecting the null that the data are independent), and one where it is less extreme.\n",
    "\n",
    "**NOTE** - \"less extreme\" just means smaller test statistic/larger p-value. Even the least extreme differences may be strongly statistically significant.\n",
    "\n",
    "Your *main* goal is the hypothesis tests, so don't spend too much time on the exploration/visualization piece. That is just a means to an end - use simple visualizations, such as boxplots or a scatter matrix (both built in to pandas), to get a feel for the overall distribution of the variables.\n",
    "\n",
    "This is challenging, so manage your time and aim for a baseline of at least running two t-tests and two Chi-squared tests before polishing. And don't forget to answer the questions in part 3, even if your results in this part aren't what you want them to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For each test, assuming statistical significance as ($p>>.05$)**\n",
    "\n",
    "$H_0: $ no significant difference between variable means.\n",
    "\n",
    "$H_A: $ statistically significant difference between means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1      object\n",
       "A2     float64\n",
       "A3     float64\n",
       "A4      object\n",
       "A5      object\n",
       "A6      object\n",
       "A7      object\n",
       "A8     float64\n",
       "A9      object\n",
       "A10     object\n",
       "A11    float64\n",
       "A12     object\n",
       "A13     object\n",
       "A14    float64\n",
       "A15    float64\n",
       "A16      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for the 6 continuous features, split into 2 data frames (approved and denied)\n",
    "cont_var = ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n",
    "credit_data['A16'] = credit_data['A16'].replace({\"+\":1, \"-\":0})\n",
    "approved = credit_data[credit_data['A16']==1]\n",
    "denied = credit_data[credit_data['A16']==0]\n",
    "\n",
    "#getting a weird error?????? but it did what I wanted so whatever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>b</td>\n",
       "      <td>32.33</td>\n",
       "      <td>7.5</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>bb</td>\n",
       "      <td>1.585</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>b</td>\n",
       "      <td>34.83</td>\n",
       "      <td>4.0</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>bb</td>\n",
       "      <td>12.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>a</td>\n",
       "      <td>38.58</td>\n",
       "      <td>5.0</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>13.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>980.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>b</td>\n",
       "      <td>44.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>10.750</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>b</td>\n",
       "      <td>44.83</td>\n",
       "      <td>7.0</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>1.625</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1     A2   A3 A4 A5  A6  A7      A8 A9 A10  A11 A12 A13    A14  A15  A16\n",
       "70  b  32.33  7.5  u  g   e  bb   1.585  t   f  0.0   t   s  420.0  0.0    0\n",
       "71  b  34.83  4.0  u  g   d  bb  12.500  t   f  0.0   t   g    NaN  0.0    0\n",
       "72  a  38.58  5.0  u  g  cc   v  13.500  t   f  0.0   t   g  980.0  0.0    0\n",
       "73  b  44.25  0.5  u  g   m   v  10.750  t   f  0.0   f   s  400.0  0.0    0\n",
       "74  b  44.83  7.0  y  p   c   v   1.625  f   f  0.0   f   g  160.0  2.0    0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denied.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6.0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5.0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14    A15  A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t  1.0   f   g  202.0    0.0    1\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t  6.0   f   g   43.0  560.0    1\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f  0.0   f   g  280.0  824.0    1\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t  5.0   t   g  100.0    3.0    1\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f  0.0   f   s  120.0    0.0    1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approved.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for A2: Ttest_indResult(statistic=4.2922156166315535, pvalue=2.0276637071781407e-05)\n",
      "Results for A3: Ttest_indResult(statistic=5.52998337614816, pvalue=4.551680702308068e-08)\n",
      "Results for A8: Ttest_indResult(statistic=8.935819983773698, pvalue=3.6710537401601785e-18)\n",
      "Results for A11: Ttest_indResult(statistic=11.667004222431277, pvalue=7.957718568079967e-29)\n",
      "Results for A14: Ttest_indResult(statistic=-2.6358251986645476, pvalue=0.008586135473979569)\n",
      "Results for A15: Ttest_indResult(statistic=4.680216020964486, pvalue=3.4520256956287944e-06)\n"
     ]
    }
   ],
   "source": [
    "#graphs didn't help. idk how to tell which one is most/least significant without looking at ttest results. gonna run it on all of them\n",
    "import scipy.stats as stats\n",
    "for col in cont_var:\n",
    "  results = stats.ttest_ind(approved[col], denied[col], nan_policy = 'omit')\n",
    "  print(\"Results for \" + col + \": \" + str((results)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most extreme statistically significant difference is in A11, with T=11.67 and pvalue=7.96e-29.\n",
    "The least extreme is A14, with T=2.64 and a pvalue of .008 (assuming significance at pvalue=.01)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A1           \n",
      "a    112   98\n",
      "b    262  206\n",
      "\n",
      "\n",
      "Chi-Squared: 0.3112832649161995\n",
      "P-value: 0.5768937883001117\n",
      "Degrees of Freedom: 1\n",
      "Expected: \n",
      " [[115.84070796  94.15929204]\n",
      " [258.15929204 209.84070796]]\n",
      "A4 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A4           \n",
      "l      0    2\n",
      "u    263  256\n",
      "y    118   45\n",
      "\n",
      "\n",
      "Chi-Squared: 26.234074966202144\n",
      "P-value: 2.010680204180363e-06\n",
      "Significant with p < 0.01!\n",
      "Degrees of Freedom: 2\n",
      "Expected: \n",
      " [[  1.11403509   0.88596491]\n",
      " [289.09210526 229.90789474]\n",
      " [ 90.79385965  72.20614035]]\n",
      "A5 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A5           \n",
      "g    263  256\n",
      "gg     0    2\n",
      "p    118   45\n",
      "\n",
      "\n",
      "Chi-Squared: 26.234074966202144\n",
      "P-value: 2.010680204180363e-06\n",
      "Significant with p < 0.01!\n",
      "Degrees of Freedom: 2\n",
      "Expected: \n",
      " [[289.09210526 229.90789474]\n",
      " [  1.11403509   0.88596491]\n",
      " [ 90.79385965  72.20614035]]\n",
      "A6 against A16: \n",
      "\n",
      "A16   0   1\n",
      "A6         \n",
      "aa   35  19\n",
      "c    75  62\n",
      "cc   12  29\n",
      "d    23   7\n",
      "e    11  14\n",
      "ff   46   7\n",
      "i    45  14\n",
      "j     7   3\n",
      "k    37  14\n",
      "m    22  16\n",
      "q    27  51\n",
      "r     1   2\n",
      "w    31  33\n",
      "x     6  32\n",
      "\n",
      "\n",
      "Chi-Squared: 98.32520342679135\n",
      "P-value: 3.4999300402715717e-15\n",
      "Significant with p < 0.01!\n",
      "Degrees of Freedom: 13\n",
      "Expected: \n",
      " [[29.97356828 24.02643172]\n",
      " [76.04405286 60.95594714]\n",
      " [22.75770925 18.24229075]\n",
      " [16.65198238 13.34801762]\n",
      " [13.87665198 11.12334802]\n",
      " [29.4185022  23.5814978 ]\n",
      " [32.74889868 26.25110132]\n",
      " [ 5.55066079  4.44933921]\n",
      " [28.30837004 22.69162996]\n",
      " [21.09251101 16.90748899]\n",
      " [43.29515419 34.70484581]\n",
      " [ 1.66519824  1.33480176]\n",
      " [35.52422907 28.47577093]\n",
      " [21.09251101 16.90748899]]\n",
      "A7 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A7           \n",
      "bb    34   25\n",
      "dd     4    2\n",
      "ff    49    8\n",
      "h     51   87\n",
      "j      5    3\n",
      "n      2    2\n",
      "o      1    1\n",
      "v    230  169\n",
      "z      2    6\n",
      "\n",
      "\n",
      "Chi-Squared: 45.03420714024056\n",
      "P-value: 3.62545287237226e-07\n",
      "Significant with p < 0.01!\n",
      "Degrees of Freedom: 8\n",
      "Expected: \n",
      " [[ 32.74889868  26.25110132]\n",
      " [  3.33039648   2.66960352]\n",
      " [ 31.63876652  25.36123348]\n",
      " [ 76.59911894  61.40088106]\n",
      " [  4.44052863   3.55947137]\n",
      " [  2.22026432   1.77973568]\n",
      " [  1.11013216   0.88986784]\n",
      " [221.47136564 177.52863436]\n",
      " [  4.44052863   3.55947137]]\n",
      "A9 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A9           \n",
      "f    306   23\n",
      "t     77  284\n",
      "\n",
      "\n",
      "Chi-Squared: 355.2038167412799\n",
      "P-value: 3.1185900878457007e-79\n",
      "Significant with p < 0.01!\n",
      "Degrees of Freedom: 1\n",
      "Expected: \n",
      " [[182.61884058 146.38115942]\n",
      " [200.38115942 160.61884058]]\n",
      "A10 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A10          \n",
      "f    297   98\n",
      "t     86  209\n",
      "\n",
      "\n",
      "Chi-Squared: 143.06956205083148\n",
      "P-value: 5.6757273745274924e-33\n",
      "Significant with p < 0.01!\n",
      "Degrees of Freedom: 1\n",
      "Expected: \n",
      " [[219.25362319 175.74637681]\n",
      " [163.74637681 131.25362319]]\n",
      "A12 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A12          \n",
      "f    213  161\n",
      "t    170  146\n",
      "\n",
      "\n",
      "Chi-Squared: 0.568273300792113\n",
      "P-value: 0.45094587758631943\n",
      "Degrees of Freedom: 1\n",
      "Expected: \n",
      " [[207.59710145 166.40289855]\n",
      " [175.40289855 140.59710145]]\n",
      "A13 against A16: \n",
      "\n",
      "A16    0    1\n",
      "A13          \n",
      "g    338  287\n",
      "p      3    5\n",
      "s     42   15\n",
      "\n",
      "\n",
      "Chi-Squared: 9.191570451545385\n",
      "P-value: 0.010094291370456357\n",
      "Degrees of Freedom: 2\n",
      "Expected: \n",
      " [[346.92028986 278.07971014]\n",
      " [  4.44057971   3.55942029]\n",
      " [ 31.63913043  25.36086957]]\n",
      "[0.5768937883001117, 2.010680204180363e-06, 2.010680204180363e-06, 3.4999300402715717e-15, 3.62545287237226e-07, 3.1185900878457007e-79, 5.6757273745274924e-33, 0.45094587758631943, 0.010094291370456357]\n"
     ]
    }
   ],
   "source": [
    "cat_var = ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n",
    "p = []\n",
    "for col in cat_var:\n",
    "  \n",
    "  ctab = pd.crosstab(credit_data[col], credit_data['A16'])\n",
    "  print(col +\" against A16: \\n\") #puts a title on the crosstab to know which cell\n",
    "  print(ctab)\n",
    "    \n",
    "  chi_squared, p_value, dof, expected = stats.chi2_contingency(ctab)\n",
    "  print(\"\\n\")\n",
    "  p.append(p_value)\n",
    "  print(f\"Chi-Squared: {chi_squared}\")\n",
    "  print(f\"P-value: {p_value}\")\n",
    "\n",
    "  if(p_value < 0.01):\n",
    "    print(\"Significant with p < 0.01!\")\n",
    "    \n",
    "  print(f\"Degrees of Freedom: {dof}\") \n",
    "  print(\"Expected: \\n\", np.array(expected))\n",
    "  print(\"\\n\") #figured out how to add line breaks. more readable. \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The smallest p value occured for `A9`: a value of $~3.116*10^{-79}$, with a $x^2$ value of $~355.2$.\n",
    "\n",
    "**The differences for `A1` and `A12` were not statistically signifcant ($p>>0.01$).\n",
    "\n",
    "**`A13` was also not statistically signifiant at ($p>>.01$), but was significant if pvalue is adjusted to ($p>.05$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZM8JckA2bgnp"
   },
   "source": [
    "## Part 3 - Analysis and Interpretation\n",
    "\n",
    "Now that you've looked at the data, answer the following questions:\n",
    "\n",
    "- Interpret and explain the two t-tests you ran - what do they tell you about the relationships between the continuous features you selected and the class labels?\n",
    "- Interpret and explain the two Chi-squared tests you ran - what do they tell you about the relationships between the categorical features you selected and the class labels?\n",
    "- What was the most challenging part of this sprint challenge?\n",
    "\n",
    "Answer with text, but feel free to intersperse example code/results or refer to it from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret and explain the two t-tests you ran - what do they tell you about the relationships between the continuous features you selected and the class labels?**\n",
    "\n",
    "Each of the continuous variables were statistically significant to some degree, with A11 having the highest significance and A14 having the lowest. This indicates that each of these variables have some direct influence in determining who is approved and who is denied credit. A lack of statistical significance would have meant a variable was evenly distributed across those who were approved, and those who were denied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret and explain the two Chi-squared tests you ran - what do they tell you about the relationships between the categorical features you selected and the class labels?**\n",
    "\n",
    "Some of the categorical variables had extremely low p-values, which suggests that they are extremely influential in the application process. These probably relate to relevant qualitative factors, such as previous loan delinquency.**\n",
    "\n",
    "A1 and A12 had high pvalues, indicating that the may not directly influence credit approval, though still have some influence. Though A13 barely missed the cutoff for significance at p > .01, it is significant at p>.05, suggesting that it may be directly related to approval status, but to a lesser degree than the other statistically significant variables.\n",
    "\n",
    "All other categorical variables appear to be directly related to approval status based on very low pvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIozLDNG2Uhu"
   },
   "source": [
    "**What was the most challenging part of this sprint challenge?**\n",
    "\n",
    "I spent a lot of time trying to decide which two columns to run t test and which two to run Chi-squared test in based on graphs, means, etc. before I decided to just test them all and look at the results that way. Once that was out of the way, interpretation was straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS Unit 1 Sprint Challenge 4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
